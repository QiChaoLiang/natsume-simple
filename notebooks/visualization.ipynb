{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect(database=\":memory:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ja_ginza_electra\"\n",
    "db = pd.read_csv(f\"../data/ted_npvs_{model_name}.csv\")\n",
    "db = pd.concat([db, pd.read_csv(f\"../data/jnlp_npvs_{model_name}.csv\")])\n",
    "# NPV＋コーパスごとに集計したいので，Pandasのvalue_counts()を利用し，その結果 (Seriesオブジェクト) をDataFrameに戻す\n",
    "db = db.value_counts().to_frame(name=\"frequency\").reset_index()\n",
    "db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパス間の頻度が比べるために一番小さいコーパスのNPVの数で正規化する\n",
    "corpus_freqs: dict[str, int] = {\n",
    "    corpus: db[db.corpus == corpus][\"frequency\"].sum() for corpus in db.corpus.unique()\n",
    "}\n",
    "min_count = min(corpus_freqs.values())\n",
    "min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_norm = {\n",
    "    corpus: min_count / frequency for corpus, frequency in corpus_freqs.items()\n",
    "}\n",
    "\n",
    "print(corpus_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[\"norm_frequency\"] = db.apply(\n",
    "    lambda r: r[\"frequency\"] * corpus_norm[r[\"corpus\"]], axis=1\n",
    ")\n",
    "db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[db.n == \"変化\"].drop(columns=[\"n\"]).to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "SELECT * FROM db\n",
    "WHERE n = ?\n",
    "GROUP BY p, n, v, corpus, frequency, norm_frequency\n",
    "ORDER BY p, norm_frequency DESC, n\n",
    "\"\"\",\n",
    "    [\"変化\"],\n",
    ").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各種の共起尺度の計算：\n",
    "-   [Relational cooccurrences and contingency tables](http://collocations.de/AM/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv-natsume-simple",
   "language": "python",
   "name": "devenv-natsume-simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "051b93bfe2e1f91d147f006f9b5e502299c33a19db14a2b4cc48dee3500e361a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
